{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2dbc7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (2.2.4)\n",
      "Requirement already satisfied: transformers in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (4.51.3)\n",
      "Requirement already satisfied: requests in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (3.1.6)\n",
      "Requirement already satisfied: tqdm in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: serpapi in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (0.1.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: packaging in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from jinja2) (3.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: networkx in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: setuptools in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/anujs101/Developer/race/.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers faiss-cpu numpy transformers requests jinja2 tqdm serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1428a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "ats_snippets = [\n",
    "    \"Use action verbs like 'Led', 'Managed', 'Developed', instead of passive phrases.\",\n",
    "    \"Quantify your achievements, e.g., 'increased sales by 20%'.\",\n",
    "    \"Keep resume length to one page unless you have 10+ years of experience.\",\n",
    "    \"Tailor your resume to each job description by including relevant keywords.\",\n",
    "    \"Use consistent formatting: bullet points, font size, spacing.\",\n",
    "    \"Avoid vague terms like 'team player', focus on specific results.\",\n",
    "    \"List technical skills and tools separately in a skills section.\",\n",
    "    \"Start each bullet point with a powerful verb.\"\n",
    "]\n",
    "\n",
    "\n",
    "cv_guide_text = \"\"\"\n",
    "Every graduate student needs a curriculum vitae, or CV   \n",
    "Your CV represents your accomplishments and experience as an academic and helps to establish your \n",
    "professional image.  Well before you apply for faculty positions, you will use your CV to apply for \n",
    "fellowships and grants, to accompany submissions for publications or conference papers, when being \n",
    "considered for leadership roles or consulting projects, and more.  CV's are also used when applying for \n",
    "some positions outside academia, such as in think tanks or research institutes, or for research positions in \n",
    "industry. \n",
    "As you progress through graduate school, you will, of course, add to your CV, but the basic areas to \n",
    "include are your contact information, education, research experience, teaching experience, publications, \n",
    "presentations, honors and awards, and contact information for your references, or those people willing to \n",
    "speak or write on your behalf.   \n",
    "Some formatting pointers: \n",
    " There is no single best format. Refer to samples for ideas, but craft your CV to best reflect you\n",
    " and your unique accomplishments.\n",
    "  Unlike a resume, there is no page limit, but most graduate student's CVs are two to five pages in\n",
    " length.  Your CV may get no more than thirty seconds of the reader's attention, so ensure the\n",
    " most important information stands out. Keep it concise and relevant!\n",
    "  Be strategic in how you order and entitle your categories.  The most important information\n",
    " should be on the first page.  Within each category, list items in reverse chronological order.\n",
    " Category headings influence how readers perceive you. For example, the same experience could\n",
    " belong in a category entitled: “Service to the Field,” “Conferences Organized,” or “Relevant\n",
    " Professional Experience.”\n",
    "  Use active verbs and sentence fragments (not full sentences) to describe your experiences. Avoid\n",
    " pronouns (e.g. I, me), and minimize articles (a, and, the). Use a level of jargon most appropriate\n",
    " for your audience. Keep locations, dates and less important information on the right side of the\n",
    " page the left side should have important details like university, degree, job title, etc.\n",
    "  Stick to a common font, such as Times New Roman, using a font size of 10 to 12 point. Use\n",
    " highlighting judiciously, favoring bold, ALL CAPS, and white space to create a crisp\n",
    " professional style.  Avoid text boxes, underlining, and shading; italics may be used in\n",
    " moderation. Margins should be equal on all four sides, and be ¾ to 1 inch in size.\n",
    "  And most importantly…Follow the conventions of your field!  Different academic disciplines\n",
    " have different standards and expectations, especially in the order of categories.  Check out CVs\n",
    " from recent graduates of your department, and others in your field, to ensure you are following\n",
    " your field's norms.\n",
    " Tailor your CV to the position, purpose, or audience \n",
    "“Why should we select YOU?” - That is the question on the top of your reader's mind, so craft your CV \n",
    "to convince the reader that you have the skills, experience, and knowledge they seek. Depending on the \n",
    "purpose, you might place more or less emphasis on your teaching experience, for example. Also, keep \n",
    "an archival CV (for your eyes only!) that lists all the details of everything you've done - tailor from \n",
    "there.\n",
    "\"\"\"\n",
    "\n",
    "chunks = [chunk.strip() for chunk in re.split(r'\\n\\s*\\n', cv_guide_text) if chunk.strip()]\n",
    "\n",
    "embeddings = model.encode(chunks)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, \"cv_guide.index\")\n",
    "with open(\"cv_guide_texts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import faiss\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# embeddings = model.encode(ats_snippets)\n",
    "\n",
    "# embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "# index.add(embeddings)\n",
    "\n",
    "# faiss.write_index(index, \"ats_guidelines.index\")\n",
    "# with open(\"ats_texts.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(ats_snippets, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cdc469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cv_guidelines(query_text, top_k=3):\n",
    "    query_embedding = model.encode([query_text]).astype(\"float32\")\n",
    "    index = faiss.read_index(\"cv_guide.index\")\n",
    "    with open(\"cv_guide_texts.pkl\", \"rb\") as f:\n",
    "        guide_chunks = pickle.load(f)\n",
    "\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return [guide_chunks[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6b16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_json = {\n",
    "    \"status\": \"success\",\n",
    "    \"message\": \"Resume extracted and classified successfully\",\n",
    "    \"data\": {\n",
    "        \"resumeId\": \"6803c9b23bfbae0fdb6f771c\",\n",
    "        \"classification\": {\n",
    "            \"contactInfo\": {\n",
    "                \"name\": \"Anuj Singh\",\n",
    "                \"email\": \"ok.anuj30@gmail.com\",\n",
    "                \"phone\": \"9301783525\",\n",
    "                \"address\": \"Mumbai\",\n",
    "                \"linkedin\": \"linkedin.com/in/anujs101/\"\n",
    "            },\n",
    "            \"education\": [\n",
    "                \"Bhartiya Vidya Bhavan Sardar Patel Institute of Technology (09/2023 - 08/2027), Bachelor of Technology - Computer Science and Engineering, Minor in Internet of Things (IoT)\"\n",
    "            ],\n",
    "            \"experience\": [\n",
    "                {\n",
    "                    \"role\": \"Head of Public Relations\",\n",
    "                    \"organization\": \"Google Developer Student Club\",\n",
    "                    \"duration\": \"Current\",\n",
    "                    \"description\": \"Collaborated with team members to organize and promote events, leading to increased participation. Developed hands-on experience in event coordination, communication, and event promotion.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"Senior Correspondent of Photography\",\n",
    "                    \"organization\": \"Spark\",\n",
    "                    \"duration\": \"Current\",\n",
    "                    \"description\": \"Lead photography team documenting college events while coordinating visual storytelling across platforms. Collaborated with editorial team on content creation and train junior photographers on technical skills.\"\n",
    "                }\n",
    "            ],\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"name\": \"Charcoal.AI - Generative AI Chatbot\",\n",
    "                    \"description\": \"Developed an AI-powered chatbot integrating Generative AI APIs (Gemini) for secure and efficient interactions. Designed a user-friendly frontend using React, ensuring seamless user experience.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"Token Launchpad\",\n",
    "                    \"description\": \"Built a decentralized token launchpad enabling users to create and deploy tokens on Solana. Integrated smart contracts for token minting, fundraising (IDO/ICO), and liquidity management.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"To-Do Application\",\n",
    "                    \"description\": \"Built a RESTful API with Node.js and Express.js, integrating MongoDB for data storage. Built a responsive and interactive front-end using React, optimizing performance with efficient state management.\"\n",
    "                }\n",
    "            ],\n",
    "            \"skills\": [\n",
    "                \"Java\",\n",
    "                \"JavaScript\",\n",
    "                \"C\",\n",
    "                \"Python\",\n",
    "                \"C++\",\n",
    "                \"Node.js\",\n",
    "                \"Express.js\",\n",
    "                \"React\",\n",
    "                \"Zod\",\n",
    "                \"RESTful API Development\",\n",
    "                \"API Testing (Postman)\",\n",
    "                \"API Integration\",\n",
    "                \"Solana dApp Development\",\n",
    "                \"Web3.js\",\n",
    "                \"Git/GitHub\",\n",
    "                \"Effective communication\",\n",
    "                \"Adaptability\",\n",
    "                \"Team Leadership\"\n",
    "            ],\n",
    "            \"certifications\": [],\n",
    "            \"achievements\": [\n",
    "                \"Completed the MERN stack development cohort under the mentorship of Harkirat Singh\",\n",
    "                \"Full Stack Development\"\n",
    "            ]\n",
    "        },\n",
    "        \"isScannedDocument\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c8ff5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_resume_json(resume_json):\n",
    "    classification = resume_json[\"data\"][\"classification\"]\n",
    "    parts = []\n",
    "\n",
    "    # Contact Info\n",
    "    contact = classification.get(\"contactInfo\", {})\n",
    "    parts.append(f\"Name: {contact.get('name', '')}\")\n",
    "    parts.append(f\"Email: {contact.get('email', '')}\")\n",
    "    parts.append(f\"Phone: {contact.get('phone', '')}\")\n",
    "    parts.append(f\"Address: {contact.get('address', '')}\")\n",
    "    parts.append(f\"LinkedIn: {contact.get('linkedin', '')}\")\n",
    "\n",
    "    # Education\n",
    "    education = classification.get(\"education\", [])\n",
    "    if education:\n",
    "        parts.append(\"\\nEducation:\")\n",
    "        for edu in education:\n",
    "            parts.append(f\"- {edu}\")\n",
    "\n",
    "    # Experience\n",
    "    experience = classification.get(\"experience\", [])\n",
    "    if experience:\n",
    "        parts.append(\"\\nExperience:\")\n",
    "        for exp in experience:\n",
    "            parts.append(f\"- {exp['role']} at {exp['organization']} ({exp['duration']}): {exp['description']}\")\n",
    "\n",
    "    # Projects\n",
    "    projects = classification.get(\"projects\", [])\n",
    "    if projects:\n",
    "        parts.append(\"\\nProjects:\")\n",
    "        for proj in projects:\n",
    "            parts.append(f\"- {proj['name']}: {proj['description']}\")\n",
    "\n",
    "    # Skills\n",
    "    skills = classification.get(\"skills\", [])\n",
    "    if skills:\n",
    "        parts.append(\"\\nSkills: \" + \", \".join(skills))\n",
    "\n",
    "    # Certifications\n",
    "    certs = classification.get(\"certifications\", [])\n",
    "    if certs:\n",
    "        parts.append(\"\\nCertifications:\")\n",
    "        for cert in certs:\n",
    "            parts.append(f\"- {cert}\")\n",
    "\n",
    "    # Achievements\n",
    "    achievements = classification.get(\"achievements\", [])\n",
    "    if achievements:\n",
    "        parts.append(\"\\nAchievements:\")\n",
    "        for ach in achievements:\n",
    "            parts.append(f\"- {ach}\")\n",
    "\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30e431c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Anuj Singh\n",
      "Email: ok.anuj30@gmail.com\n",
      "Phone: 9301783525\n",
      "Address: Mumbai\n",
      "LinkedIn: linkedin.com/in/anujs101/\n",
      "\n",
      "Education:\n",
      "- Bhartiya Vidya Bhavan Sardar Patel Institute of Technology (09/2023 - 08/2027), Bachelor of Technology - Computer Science and Engineering, Minor in Internet of Things (IoT)\n",
      "\n",
      "Experience:\n",
      "- Head of Public Relations at Google Developer Student Club (Current): Collaborated with team members to organize and promote events, leading to increased participation. Developed hands-on experience in event coordination, communication, and event promotion.\n",
      "- Senior Correspondent of Photography at Spark (Current): Lead photography team documenting college events while coordinating visual storytelling across platforms. Collaborated with editorial team on content creation and train junior photographers on technical skills.\n",
      "\n",
      "Projects:\n",
      "- Charcoal.AI - Generative AI Chatbot: Developed an AI-powered chatbot integrating Generative AI APIs (Gemini) for secure and efficient interactions. Designed a user-friendly frontend using React, ensuring seamless user experience.\n",
      "- Token Launchpad: Built a decentralized token launchpad enabling users to create and deploy tokens on Solana. Integrated smart contracts for token minting, fundraising (IDO/ICO), and liquidity management.\n",
      "- To-Do Application: Built a RESTful API with Node.js and Express.js, integrating MongoDB for data storage. Built a responsive and interactive front-end using React, optimizing performance with efficient state management.\n",
      "\n",
      "Skills: Java, JavaScript, C, Python, C++, Node.js, Express.js, React, Zod, RESTful API Development, API Testing (Postman), API Integration, Solana dApp Development, Web3.js, Git/GitHub, Effective communication, Adaptability, Team Leadership\n",
      "\n",
      "Achievements:\n",
      "- Completed the MERN stack development cohort under the mentorship of Harkirat Singh\n",
      "- Full Stack Development\n"
     ]
    }
   ],
   "source": [
    "print(flatten_resume_json(resume_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ad61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def embed_resume_for_future_matching(resume_text):\n",
    "    emb = model.encode([resume_text]).astype(\"float32\")\n",
    "    index = faiss.IndexFlatL2(emb.shape[1])\n",
    "    index.add(emb)\n",
    "    faiss.write_index(index, \"resume_vectors.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701c32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = flatten_resume_json(resume_json)\n",
    "rag_context = retrieve_cv_guidelines(resume_text, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5c81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import requests\n",
    "\n",
    "def build_prompt(resume_text, rag_context):\n",
    "    return f\"\"\"\n",
    "You are a resume enhancement AI.\n",
    "\n",
    "From the following raw resume data and RAG context, extract and rewrite content into structured professional resume sections: About, Skills, Experience, Education, Projects, Certifications, and Achievements.\n",
    "\n",
    "Only return the enhanced resume content. Content should fit into a single page. Do NOT include any explanations, notes, or repeat the prompt.\n",
    "=== RAG CONTEXT ===\n",
    "{rag_context}\n",
    "=== Resume Input ===\n",
    "{resume_text}\n",
    "\n",
    "=== Enhanced Resume ===\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9612ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "def query_groq(prompt, model=\"llama3-8b-8192\"):\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a resume enhancer AI. Output structured resume sections only.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1024\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7718e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(resume_text, rag_context)\n",
    "enhanced_resume = query_groq(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d4f4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_enhanced_resume(raw_text):\n",
    "    import re\n",
    "\n",
    "    # Define section headings\n",
    "    section_titles = [\n",
    "        \"About\", \"Skills\", \"Experience\", \"Education\", \"Projects\",\n",
    "        \"Certifications\", \"Achievements\"\n",
    "    ]\n",
    "\n",
    "    sections = {title.lower(): [] for title in section_titles}\n",
    "    current_section = None\n",
    "\n",
    "    lines = raw_text.strip().splitlines()\n",
    "    for line in lines:\n",
    "        # Detect section header\n",
    "        match = re.match(r\"\\*\\*(.*?)\\*\\*\", line.strip())\n",
    "        if match:\n",
    "            header = match.group(1).strip()\n",
    "            if header in section_titles:\n",
    "                current_section = header.lower()\n",
    "                continue\n",
    "\n",
    "        # Store lines under the current section\n",
    "        if current_section:\n",
    "            content = line.strip(\"•\").strip(\"-\").strip()\n",
    "            if content:\n",
    "                sections[current_section].append(content)\n",
    "\n",
    "    return sections\n",
    "\n",
    "metadata = resume_json[\"data\"][\"classification\"][\"contactInfo\"]\n",
    "parsed_data = parse_enhanced_resume(enhanced_resume)\n",
    "# resume_data = {\n",
    "#     \"name\": metadata.get(\"name\", \"\"),\n",
    "#     \"email\": metadata.get(\"email\", \"\"),\n",
    "#     \"phone\": metadata.get(\"phone\", \"\"),\n",
    "#     \"address\": metadata.get(\"address\", \"\"),\n",
    "#     \"linkedin\": metadata.get(\"linkedin\", \"\"),\n",
    "#     \"about\": \" \".join(parsed_data.get(\"about\", [])) or \"N/A\",\n",
    "#     \"skills\": parsed_data.get(\"skills\", []),\n",
    "#     \"experience\": [],  \n",
    "#     \"education\": [], \n",
    "#     \"projects\": [],  \n",
    "#     \"certifications\": parsed_data.get(\"certifications\", []),\n",
    "#     \"achievements\": parsed_data.get(\"achievements\", []),\n",
    "# }\n",
    "\n",
    "resume_data = {\n",
    "    \"name\": metadata.get(\"name\", \"\"),\n",
    "    \"email\": metadata.get(\"email\", \"\"),\n",
    "    \"phone\": metadata.get(\"phone\", \"\"),\n",
    "    \"address\": metadata.get(\"address\", \"\"),\n",
    "    \"linkedin\": metadata.get(\"linkedin\", \"\"),\n",
    "    \"about\": \" \".join(parsed_data.get(\"about\", [])) or \"N/A\",\n",
    "    \"skills\": parsed_data.get(\"skills\", []),\n",
    "    \"experience\": parsed_data.get(\"experience\", []),\n",
    "    \"education\": parsed_data.get(\"education\", []),\n",
    "    \"projects\": parsed_data.get(\"projects\", []),\n",
    "    \"certifications\": parsed_data.get(\"certifications\", []),\n",
    "    \"achievements\": parsed_data.get(\"achievements\", []),\n",
    "}\n",
    "\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "def render_latex(resume_data, template_path=\"resume_template.tex\"):\n",
    "    env = Environment(loader=FileSystemLoader('.'))\n",
    "    template = env.get_template(template_path)\n",
    "    return template.render(resume_data)\n",
    "\n",
    "latex_code = render_latex(resume_data)\n",
    "\n",
    "with open(\"resume_output.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f89faeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import serpapi\n",
    "import json\n",
    "def get_multiple_jobs_with_pagination(job_title, location):\n",
    "    params = {\n",
    "        \"engine\": \"google_jobs\",\n",
    "        \"q\": job_title,\n",
    "        \"location\": location,\n",
    "        \"api_key\": '83c1ef3c99b32b05ab29da61937948e1cce626b355feb3c4c6ead197a08a7aac',\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"in\"\n",
    "    }\n",
    "    max_jobs = 5\n",
    "    all_jobs = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(all_jobs) < max_jobs:\n",
    "        if next_page_token:\n",
    "            params[\"next_page_token\"] = next_page_token\n",
    "        else:\n",
    "            params.pop(\"next_page_token\", None)\n",
    "\n",
    "        search = serpapi.search(params)   # returns SerpResults (dict-like)\n",
    "        data = search          \n",
    "\n",
    "        jobs = data.get(\"jobs_results\", [])\n",
    "        all_jobs.extend(jobs)\n",
    "\n",
    "        # Pagination\n",
    "        serpapi_pagination = data.get(\"serpapi_pagination\", {})\n",
    "        next_page_token = serpapi_pagination.get(\"next_page_token\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    all_jobs = all_jobs[:max_jobs]\n",
    "\n",
    "    # result = {}\n",
    "    # for idx, job in enumerate(all_jobs, 1):\n",
    "    #     description = job.get('description', '')\n",
    "    #     company_name = job.get('company_name', '')\n",
    "    #     application_link = \"\"\n",
    "    #     if 'apply_options' in job and job['apply_options']:\n",
    "    #         application_link = job['apply_options'][0].get('link', '')\n",
    "    #     elif 'via' in job:\n",
    "    #         application_link = job['via']\n",
    "    #     else:\n",
    "    #         application_link = job.get('detected_extensions', {}).get('apply_link', '')\n",
    "    #     result[f\"{job_title} Opportunity {idx}\"] = {\n",
    "    #         \"company_name\": company_name,\n",
    "    #         \"description\": description,\n",
    "    #         \"application_link\": application_link\n",
    "    #     }\n",
    "\n",
    "    result = {}\n",
    "    for idx, job in enumerate(all_jobs, 1):\n",
    "        description = job.get('description', '')\n",
    "        company_name = job.get('company_name', '')\n",
    "        application_link = \"\"\n",
    "        if 'apply_options' in job and job['apply_options']:\n",
    "            application_link = job['apply_options'][0].get('link', '')\n",
    "        elif 'via' in job:\n",
    "            application_link = job['via']\n",
    "        else:\n",
    "            application_link = job.get('detected_extensions', {}).get('apply_link', '')\n",
    "        \n",
    "        actual_job_title = job.get('title', f\"{job_title} Opportunity {idx}\")\n",
    "        result[actual_job_title] = {\n",
    "            \"company_name\": company_name,\n",
    "            \"description\": description,\n",
    "            \"application_link\": application_link\n",
    "        }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5785a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = \"Python Developer\"\n",
    "location = \"India\"\n",
    "job_descriptions_json = get_multiple_jobs_with_pagination(job_title, location)\n",
    "\n",
    "# Step 2: Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 3: Extract descriptions and metadata\n",
    "descriptions = []\n",
    "metadata = []\n",
    "\n",
    "for title, data in job_descriptions_json.items():\n",
    "    descriptions.append(data[\"description\"])\n",
    "    metadata.append({\n",
    "        \"title\": title,\n",
    "        \"company_name\": data[\"company_name\"],\n",
    "        \"application_link\": data[\"application_link\"]\n",
    "    })\n",
    "\n",
    "# Step 4: Generate embeddings\n",
    "embeddings = model.encode(descriptions)\n",
    "embeddings_np = np.array(embeddings).astype(\"float32\")  # FAISS requires float32\n",
    "\n",
    "# Step 5: Create FAISS index and add embeddings\n",
    "dimension = embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings_np)\n",
    "\n",
    "# Optional: Save FAISS index\n",
    "faiss.write_index(index, \"job_faiss.index\")\n",
    "\n",
    "# Step 6: Save metadata for lookup\n",
    "with open(\"job_faiss_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "134f8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"job_faiss.index\")\n",
    "with open(\"job_faiss_metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cd98044",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_resume_text = enhanced_resume\n",
    "\n",
    "resume_embedding = model.encode([user_resume_text]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0a4b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matching Jobs:\n",
      "\n",
      "smartSense Consulting Solutions - Python Developer - Server Side Component at smartSense Consulting Solutions\n",
      "Link: https://in.linkedin.com/jobs/view/smartsense-consulting-solutions-python-developer-server-side-component-at-smartsense-consulting-solutions-4206287397?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
      "\n",
      "Junior Python Developer at Dehazelabs\n",
      "Link: https://jobs.ashbyhq.com/dehazelabs/3fc045c8-c43d-4523-b258-80e35b2930ed?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
      "\n",
      "Python+Snowflake Developer - SA/M - GO/JC/21441/2025 at Golden Opportunities\n",
      "Link: https://in.linkedin.com/jobs/view/python%2Bsnowflake-developer-sa-m-go-jc-21441-2025-at-golden-opportunities-4204686847?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "D, I = index.search(resume_embedding, top_k)\n",
    "\n",
    "print(\"Top Matching Jobs:\\n\")\n",
    "for idx in I[0]:\n",
    "    job = metadata[idx]\n",
    "    print(f\"{job['title']} at {job['company_name']}\\nLink: {job['application_link']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8db19079",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc_text = \"\\n\\n\".join([metadata[i][\"title\"] + \":\\n\" + descriptions[i] for i in I[0]])\n",
    "\n",
    "rag_prompt = f\"\"\"\n",
    "You are a career advisor AI. The following is a candidate's resume:\n",
    "\n",
    "--- RESUME ---\n",
    "{user_resume_text}\n",
    "\n",
    "These are the job descriptions of top matches:\n",
    "\n",
    "--- JOB DESCRIPTIONS ---\n",
    "{job_desc_text}\n",
    "\n",
    "1. Identify what technical or domain-specific skills the candidate is missing.\n",
    "2. Recommend a step-by-step learning path (with topics/tools/technologies) to bridge the gap.\n",
    "3. Suggest resources (platforms or certifications) for each skill if possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bb2a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = query_groq(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "707058fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cover_letter(user_resume, selected_job_title, selected_job_description, company_name):\n",
    "    prompt = f\"\"\"\n",
    "Write a personalized and professional cover letter for the position of \"{selected_job_title}\" at {company_name}.\n",
    "The letter should be 3-4 paragraphs, tailored to the job description below, and should highlight how the candidate's skills align with the company's requirements.\n",
    "\n",
    "--- Candidate's Resume ---\n",
    "{user_resume}\n",
    "\n",
    "--- Job Description ---\n",
    "{selected_job_description}\n",
    "\n",
    "Ensure the tone is confident, enthusiastic, and formal. Avoid generic phrases. Mention specific skills or experiences from the resume that match the job. End with a call to action and interest in an interview.\n",
    "Begin your response directly from the actual response, no need to give headers like 'Here is your generated cover letter'.\n",
    "\"\"\"\n",
    "\n",
    "    return query_groq(prompt, model=\"llama3-8b-8192\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7f389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cover letter to a .txt file\n",
    "def save_cover_letter_to_txt(cover_letter_text, filename=\"cover_letter.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cover_letter_text)\n",
    "    print(f\"Cover letter saved as '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "778fd2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover letter saved as 'cover_letter.txt'\n"
     ]
    }
   ],
   "source": [
    "# Let's say the user selects job index 1 (second from search results)\n",
    "selected_index = I[0][1]\n",
    "selected_job = metadata[selected_index]\n",
    "\n",
    "selected_title = selected_job.get(\"title\", \"Python Developer\")  # fallback\n",
    "selected_description = descriptions[selected_index]\n",
    "selected_company = selected_job[\"company_name\"]\n",
    "\n",
    "cover_letter = generate_cover_letter(\n",
    "    user_resume=user_resume_text,\n",
    "    selected_job_title=selected_title,\n",
    "    selected_job_description=selected_description,\n",
    "    company_name=selected_company\n",
    ")\n",
    "\n",
    "save_cover_letter_to_txt(cover_letter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
