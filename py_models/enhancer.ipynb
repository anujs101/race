{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a45fc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import time\n",
    "import serpapi\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1428a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "ats_snippets = [\n",
    "    \"Use action verbs like 'Led', 'Managed', 'Developed', instead of passive phrases.\",\n",
    "    \"Quantify your achievements, e.g., 'increased sales by 20%'.\",\n",
    "    \"Keep resume length to one page unless you have 10+ years of experience.\",\n",
    "    \"Tailor your resume to each job description by including relevant keywords.\",\n",
    "    \"Use consistent formatting: bullet points, font size, spacing.\",\n",
    "    \"Avoid vague terms like 'team player', focus on specific results.\",\n",
    "    \"List technical skills and tools separately in a skills section.\",\n",
    "    \"Start each bullet point with a powerful verb.\"\n",
    "]\n",
    "\n",
    "chunks = [chunk.strip() for chunk in ats_snippets if chunk.strip()]\n",
    "\n",
    "embeddings = model.encode(chunks)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, \"cv_guide.index\")\n",
    "with open(\"cv_guide_texts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4cdc469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cv_guidelines(query_text, top_k=3):\n",
    "    query_embedding = model.encode([query_text]).astype(\"float32\")\n",
    "    index = faiss.read_index(\"cv_guide.index\")\n",
    "    with open(\"cv_guide_texts.pkl\", \"rb\") as f:\n",
    "        guide_chunks = pickle.load(f)\n",
    "\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return [guide_chunks[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba6b16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_json = {\n",
    "    \"status\": \"success\",\n",
    "    \"message\": \"Resume extracted and classified successfully\",\n",
    "    \"data\": {\n",
    "        \"resumeId\": \"6803c9b23bfbae0fdb6f771c\",\n",
    "        \"classification\": {\n",
    "            \"contactInfo\": {\n",
    "                \"name\": \"Anuj Singh\",\n",
    "                \"email\": \"ok.anuj30@gmail.com\",\n",
    "                \"phone\": \"9301783525\",\n",
    "                \"address\": \"Mumbai\",\n",
    "                \"linkedin\": \"linkedin.com/in/anujs101/\"\n",
    "            },\n",
    "            \"education\": [\n",
    "                \"Bhartiya Vidya Bhavan Sardar Patel Institute of Technology (09/2023 - 08/2027), Bachelor of Technology - Computer Science and Engineering, Minor in Internet of Things (IoT)\"\n",
    "            ],\n",
    "            \"experience\": [\n",
    "                {\n",
    "                    \"role\": \"Head of Public Relations\",\n",
    "                    \"organization\": \"Google Developer Student Club\",\n",
    "                    \"duration\": \"Current\",\n",
    "                    \"description\": \"Collaborated with team members to organize and promote events, leading to increased participation. Developed hands-on experience in event coordination, communication, and event promotion.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"Senior Correspondent of Photography\",\n",
    "                    \"organization\": \"Spark\",\n",
    "                    \"duration\": \"Current\",\n",
    "                    \"description\": \"Lead photography team documenting college events while coordinating visual storytelling across platforms. Collaborated with editorial team on content creation and train junior photographers on technical skills.\"\n",
    "                }\n",
    "            ],\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"name\": \"Charcoal.AI - Generative AI Chatbot\",\n",
    "                    \"description\": \"Developed an AI-powered chatbot integrating Generative AI APIs (Gemini) for secure and efficient interactions. Designed a user-friendly frontend using React, ensuring seamless user experience.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"Token Launchpad\",\n",
    "                    \"description\": \"Built a decentralized token launchpad enabling users to create and deploy tokens on Solana. Integrated smart contracts for token minting, fundraising (IDO/ICO), and liquidity management.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"To-Do Application\",\n",
    "                    \"description\": \"Built a RESTful API with Node.js and Express.js, integrating MongoDB for data storage. Built a responsive and interactive front-end using React, optimizing performance with efficient state management.\"\n",
    "                }\n",
    "            ],\n",
    "            \"skills\": [\n",
    "                \"Java\",\n",
    "                \"JavaScript\",\n",
    "                \"C\",\n",
    "                \"Python\",\n",
    "                \"C++\",\n",
    "                \"Node.js\",\n",
    "                \"Express.js\",\n",
    "                \"React\",\n",
    "                \"Zod\",\n",
    "                \"RESTful API Development\",\n",
    "                \"API Testing (Postman)\",\n",
    "                \"API Integration\",\n",
    "                \"Solana dApp Development\",\n",
    "                \"Web3.js\",\n",
    "                \"Git/GitHub\",\n",
    "                \"Effective communication\",\n",
    "                \"Adaptability\",\n",
    "                \"Team Leadership\"\n",
    "            ],\n",
    "            \"certifications\": [],\n",
    "            \"achievements\": [\n",
    "                \"Completed the MERN stack development cohort under the mentorship of Harkirat Singh\",\n",
    "                \"Full Stack Development\"\n",
    "            ]\n",
    "        },\n",
    "        \"isScannedDocument\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c8ff5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_resume_json(resume_json):\n",
    "    classification = resume_json[\"data\"][\"classification\"]\n",
    "    parts = []\n",
    "\n",
    "    # Contact Info\n",
    "    contact = classification.get(\"contactInfo\", {})\n",
    "    parts.append(f\"Name: {contact.get('name', '')}\")\n",
    "    parts.append(f\"Email: {contact.get('email', '')}\")\n",
    "    parts.append(f\"Phone: {contact.get('phone', '')}\")\n",
    "    parts.append(f\"Address: {contact.get('address', '')}\")\n",
    "    parts.append(f\"LinkedIn: {contact.get('linkedin', '')}\")\n",
    "\n",
    "    # Education\n",
    "    education = classification.get(\"education\", [])\n",
    "    if education:\n",
    "        parts.append(\"\\nEducation:\")\n",
    "        for edu in education:\n",
    "            parts.append(f\"- {edu}\")\n",
    "\n",
    "    # Experience\n",
    "    experience = classification.get(\"experience\", [])\n",
    "    if experience:\n",
    "        parts.append(\"\\nExperience:\")\n",
    "        for exp in experience:\n",
    "            parts.append(f\"- {exp['role']} at {exp['organization']} ({exp['duration']}): {exp['description']}\")\n",
    "\n",
    "    # Projects\n",
    "    projects = classification.get(\"projects\", [])\n",
    "    if projects:\n",
    "        parts.append(\"\\nProjects:\")\n",
    "        for proj in projects:\n",
    "            parts.append(f\"- {proj['name']}: {proj['description']}\")\n",
    "\n",
    "    # Skills\n",
    "    skills = classification.get(\"skills\", [])\n",
    "    if skills:\n",
    "        parts.append(\"\\nSkills: \" + \", \".join(skills))\n",
    "\n",
    "    # Certifications\n",
    "    certs = classification.get(\"certifications\", [])\n",
    "    if certs:\n",
    "        parts.append(\"\\nCertifications:\")\n",
    "        for cert in certs:\n",
    "            parts.append(f\"- {cert}\")\n",
    "\n",
    "    # Achievements\n",
    "    achievements = classification.get(\"achievements\", [])\n",
    "    if achievements:\n",
    "        parts.append(\"\\nAchievements:\")\n",
    "        for ach in achievements:\n",
    "            parts.append(f\"- {ach}\")\n",
    "\n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73ad61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_resume_for_future_matching(resume_text):\n",
    "    emb = model.encode([resume_text]).astype(\"float32\")\n",
    "    index = faiss.IndexFlatL2(emb.shape[1])\n",
    "    index.add(emb)\n",
    "    faiss.write_index(index, \"resume_vectors.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e5c81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(resume_json):\n",
    "    resume_text = flatten_resume_json(resume_json)\n",
    "    rag_context = retrieve_cv_guidelines(resume_text, top_k=3)\n",
    "    embed_resume_for_future_matching(resume_text)\n",
    "\n",
    "    return f\"\"\"\n",
    "        You are a resume enhancement AI.\n",
    "\n",
    "        From the following raw resume data and RAG context, extract and rewrite content into structured professional resume sections: About, Skills, Experience, Education, Projects, Certifications, and Achievements.\n",
    "\n",
    "        Only return the enhanced resume content. Content should fit into a single page. Do NOT include any explanations, notes, or repeat the prompt.\n",
    "        === RAG CONTEXT ===\n",
    "        {rag_context}\n",
    "        === Resume Input ===\n",
    "        {resume_text}\n",
    "\n",
    "        === Enhanced Resume ===\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9612ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_groq(prompt, model=\"llama3-8b-8192\"):\n",
    "    GROQ_API_KEY = \"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\"\n",
    "\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a resume enhancer AI. Output structured resume sections only.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1024\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d4f4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_enhanced_resume(resume_json):\n",
    "    enhancement_prompt = build_prompt(resume_json)\n",
    "    raw_text = query_groq(enhancement_prompt)\n",
    "\n",
    "    metadata = resume_json[\"data\"][\"classification\"][\"contactInfo\"]\n",
    "    section_titles = [\n",
    "        \"About\", \"Skills\", \"Experience\", \"Education\", \"Projects\",\n",
    "        \"Certifications\", \"Achievements\"\n",
    "    ]\n",
    "\n",
    "    sections = {title.lower(): [] for title in section_titles}\n",
    "    current_section = None\n",
    "\n",
    "    lines = raw_text.strip().splitlines()\n",
    "    for line in lines:\n",
    "        # Detect section headers like **Skills**\n",
    "        match = re.match(r\"\\*\\*(.*?)\\*\\*\", line.strip())\n",
    "        if match:\n",
    "            header = match.group(1).strip()\n",
    "            if header in section_titles:\n",
    "                current_section = header.lower()\n",
    "                continue\n",
    "\n",
    "        # Store content lines under the current section\n",
    "        if current_section:\n",
    "            content = line.strip(\"â€¢\").strip(\"-\").strip()\n",
    "            if content:\n",
    "                sections[current_section].append(content)\n",
    "\n",
    "    # Now build the final resume JSON\n",
    "    def get_single_line(section_name):\n",
    "        items = sections.get(section_name.lower(), [])\n",
    "        return items[0] if items else \"\"\n",
    "\n",
    "    def clean_items(items):\n",
    "        if items is None:\n",
    "            return []\n",
    "        cleaned = []\n",
    "        for item in items:\n",
    "            item = item.lstrip('*+â€¢- ').strip()\n",
    "            cleaned.append(item)\n",
    "        return cleaned\n",
    "\n",
    "    parsed_resume = {\n",
    "        \"name\": metadata.get(\"name\", \"\"),\n",
    "        \"email\": metadata.get(\"email\", \"\"),\n",
    "        \"phone\": metadata.get(\"phone\", \"\"),\n",
    "        \"address\": metadata.get(\"address\", \"\"),\n",
    "        \"linkedin\": metadata.get(\"linkedin\", \"\"),\n",
    "        \"about\": get_single_line(\"About\"),\n",
    "        \"skills\": clean_items(sections.get(\"skills\", [])),\n",
    "        \"experience\": clean_items(sections.get(\"experience\", [])),\n",
    "        \"education\": clean_items(sections.get(\"education\", [])),\n",
    "        \"projects\": clean_items(sections.get(\"projects\", [])),\n",
    "        \"certifications\": clean_items(sections.get(\"certifications\", [])),\n",
    "        \"achievements\": clean_items(sections.get(\"achievements\", []))\n",
    "    }\n",
    "\n",
    "    return parsed_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a8fe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_latex(resume_json, template_path=\"resume_template.tex\"):\n",
    "    resume_data = parse_enhanced_resume(resume_json)\n",
    "    \n",
    "    env = Environment(loader=FileSystemLoader('.'))\n",
    "    template = env.get_template(template_path)\n",
    "    latex_code =  template.render(resume_data)\n",
    "    with open(\"resume_output.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(latex_code)\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f89faeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_jobs_with_pagination(job_title, location):\n",
    "    params = {\n",
    "        \"engine\": \"google_jobs\",\n",
    "        \"q\": job_title,\n",
    "        \"location\": location,\n",
    "        \"api_key\": '83c1ef3c99b32b05ab29da61937948e1cce626b355feb3c4c6ead197a08a7aac',\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"in\"\n",
    "    }\n",
    "    max_jobs = 5\n",
    "    all_jobs = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(all_jobs) < max_jobs:\n",
    "        if next_page_token:\n",
    "            params[\"next_page_token\"] = next_page_token\n",
    "        else:\n",
    "            params.pop(\"next_page_token\", None)\n",
    "\n",
    "        search = serpapi.search(params)   # returns SerpResults (dict-like)\n",
    "        data = search          \n",
    "\n",
    "        jobs = data.get(\"jobs_results\", [])\n",
    "        all_jobs.extend(jobs)\n",
    "\n",
    "        # Pagination\n",
    "        serpapi_pagination = data.get(\"serpapi_pagination\", {})\n",
    "        next_page_token = serpapi_pagination.get(\"next_page_token\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    all_jobs = all_jobs[:max_jobs]\n",
    "\n",
    "    result = {}\n",
    "    for idx, job in enumerate(all_jobs, 1):\n",
    "        description = job.get('description', '')\n",
    "        company_name = job.get('company_name', '')\n",
    "        application_link = \"\"\n",
    "        if 'apply_options' in job and job['apply_options']:\n",
    "            application_link = job['apply_options'][0].get('link', '')\n",
    "        elif 'via' in job:\n",
    "            application_link = job['via']\n",
    "        else:\n",
    "            application_link = job.get('detected_extensions', {}).get('apply_link', '')\n",
    "        \n",
    "        actual_job_title = job.get('title', f\"{job_title} Opportunity {idx}\")\n",
    "        result[actual_job_title] = {\n",
    "            \"company_name\": company_name,\n",
    "            \"description\": description,\n",
    "            \"application_link\": application_link\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = \"Python Developer\"\n",
    "location = \"India\"\n",
    "\n",
    "def embed_job_data(job_title, location):\n",
    "    job_descriptions_json = get_multiple_jobs_with_pagination(job_title, location)\n",
    "\n",
    "    descriptions = []\n",
    "    metadata = []\n",
    "\n",
    "    for title, data in job_descriptions_json.items():\n",
    "        description = data.get(\"description\", \"\")\n",
    "        descriptions.append(description)\n",
    "\n",
    "        metadata.append({\n",
    "            \"title\": title,\n",
    "            \"company_name\": data.get(\"company_name\", \"\"),\n",
    "            \"application_link\": data.get(\"application_link\", \"\"),\n",
    "            \"description\": description  # ðŸ”¥ also saving description inside metadata now\n",
    "        })\n",
    "\n",
    "    # Step 4: Generate embeddings\n",
    "    embeddings = model.encode(descriptions)\n",
    "    embeddings_np = np.array(embeddings).astype(\"float32\")  # FAISS requires float32\n",
    "\n",
    "    # Step 5: Create FAISS index and add embeddings\n",
    "    dimension = embeddings_np.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings_np)\n",
    "\n",
    "    # Optional: Save FAISS index\n",
    "    faiss.write_index(index, \"job_faiss.index\")\n",
    "\n",
    "    # Step 6: Save metadata (with descriptions) for lookup\n",
    "    with open(\"job_faiss_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5de59828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_jobs(resume_json):\n",
    "    enhanced_resume = parse_enhanced_resume(resume_json)\n",
    "    render_latex(resume_json)\n",
    "\n",
    "    index = faiss.read_index(\"job_faiss.index\")\n",
    "    \n",
    "    with open(\"job_faiss_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Ensure model is loaded\n",
    "    resume_embedding = model.encode([enhanced_resume]).astype(\"float32\")\n",
    "\n",
    "    top_k = 3\n",
    "    D, I = index.search(resume_embedding, top_k)\n",
    "\n",
    "    matched_jobs = []\n",
    "\n",
    "    for idx in I[0]:\n",
    "        job = metadata[idx]\n",
    "        matched_jobs.append({\n",
    "            \"title\": job.get('title', ''),\n",
    "            \"company_name\": job.get('company_name', ''),\n",
    "            \"application_link\": job.get('application_link', ''),\n",
    "            \"description\": job.get('description', '')  # ðŸ”¥ Include description now\n",
    "        })\n",
    "    \n",
    "    return json.dumps({\"matched_jobs\": matched_jobs}, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8db19079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_learning_path(resume_json) :\n",
    "    enhanced_resume = parse_enhanced_resume(resume_json)\n",
    "    job_desc = match_jobs(resume_json)\n",
    "    rag_prompt = f\"\"\"\n",
    "        You are a career advisor AI. The following is a candidate's resume:\n",
    "\n",
    "        --- RESUME ---\n",
    "        {enhanced_resume}\n",
    "\n",
    "        These are the job descriptions of top matches:\n",
    "\n",
    "        --- JOB DESCRIPTIONS ---\n",
    "        {job_desc}\n",
    "\n",
    "        1. Identify what technical or domain-specific skills the candidate is missing.\n",
    "        2. Recommend a step-by-step learning path (with topics/tools/technologies) to bridge the gap.\n",
    "        3. Suggest resources (platforms or certifications) for each skill if possible.\n",
    "    \"\"\"\n",
    "    \n",
    "    return query_groq(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b54bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = generate_learning_path(resume_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "707058fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cover_letter(resume_json, selected_job_title, selected_job_description, company_name):\n",
    "    enhance_resume = parse_enhanced_resume(resume_json)\n",
    "    prompt = f\"\"\"\n",
    "        Write a personalized and professional cover letter for the position of \"{selected_job_title}\" at {company_name}.\n",
    "        The letter should be 3-4 paragraphs, tailored to the job description below, and should highlight how the candidate's skills align with the company's requirements.\n",
    "\n",
    "        --- Candidate's Resume ---\n",
    "        {enhance_resume}\n",
    "\n",
    "        --- Job Description ---\n",
    "        {selected_job_description}\n",
    "\n",
    "        Ensure the tone is confident, enthusiastic, and formal. Avoid generic phrases. Mention specific skills or experiences from the resume that match the job. End with a call to action and interest in an interview.\n",
    "        Begin your response directly from the actual response, no need to give headers like 'Here is your generated cover letter'.\n",
    "    \"\"\"\n",
    "\n",
    "    return query_groq(prompt, model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a7f389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cover letter to a .txt file\n",
    "def save_cover_letter_to_txt(cover_letter_text, filename=\"cover_letter.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cover_letter_text)\n",
    "    print(f\"Cover letter saved as '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fd2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"matched_jobs\": [\n",
      "    {\n",
      "      \"title\": \"Principal Python Developer\",\n",
      "      \"company_name\": \"Michael Page\",\n",
      "      \"application_link\": \"https://www.michaelpage.co.in/job-detail/principal-python-developer/ref/jn-022025-6664599?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\",\n",
      "      \"description\": \"â€¢ Fast track growth & PnL ownership\\nâ€¢ Handling multiple clients\\n\\nAbout Our Client\\n\\nOur client is a renowned name in the industrial automation space.\\n\\nJob Description\\nâ€¢ Full Stack Development: Lead the design and development of end-to-end software solutions with a focus on server-side Python development and client-side Vue.js development.\\nâ€¢ Architecture and Design: Collaborate with cross-functional teams to design complex software systems meeting business requirements and performance goals.\\nâ€¢ Code Review and Quality Assurance: Conduct thorough code reviews to ensure code quality, adherence to best practices and consistency. Implement and enforce coding standards across the development team.\\nâ€¢ Technical Leadership: Provide technical guidance and mentor junior developers by sharing knowledge with the team. Keep up to date regarding industry best practice and emerging technologies.\\nâ€¢ Problem Solving: Analyze and troubleshoot complex issues and propose effective solutions promptly. Demonstrate a proactive problem-solving and debugging approach.\\nâ€¢ Documentation: Create and maintain comprehensive technical documentation for developed systems, APIs and workflows.\\nâ€¢ Continuous Improvement: Actively participate in process improvement initiatives and contribute to the overall improvement of development processes and methodologies.\\n\\nThe Successful Applicant\\nâ€¢ Master's degree in computer science, computer application or information technology\\nâ€¢ 10+ years of professional software development experience\\nâ€¢ Expert-level proficiency in Python and JS\\nâ€¢ Deep understanding of object-oriented programming (OOP) and clean code principles\\nâ€¢ Strong knowledge of web development technologies, frameworks and libraries (e. g. Django, Vue.js)\\nâ€¢ Experience with RESTful API design and implementation\\nâ€¢ Experience in testing of web applications (unit, integration and system tests)\\nâ€¢ Familiarity with version control systems like Git and application lifecycle systems\\nâ€¢ Experience with virtualization environments like Docker and the orchestration of containers\\nâ€¢ Very good English skills\\nâ€¢ Ability to work individually and in an international agile team\\n\\nWhat's on Offer\\nâ€¢ Challenging work on cutting-edge software technologies with a clear product focus\\nâ€¢ Collaboration with our agile Indo-German team\\nâ€¢ Dynamic work environment with many opportunities for personal growth\\nâ€¢ Access to on-the-job and off-the-job learning opportunities\\nâ€¢ Flexible, hybrid working arrangements\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Software Engineer II - Python\",\n",
      "      \"company_name\": \"Blue Yonder\",\n",
      "      \"application_link\": \"https://in.linkedin.com/jobs/view/software-engineer-ii-python-at-blue-yonder-4213586858?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\",\n",
      "      \"description\": \"Scope\\nâ€¢ Core responsibilities to include analyze business requirements and designs for accuracy and completeness. Develops and maintains relevant product.\\n\\nOur Current Technical Environment\\nâ€¢ Software: Python, GIT, Rest API, OAuth\\nâ€¢ Application Architecture: Scalable, Resilient, event driven, secure multi-tenant Microservices architecture\\nâ€¢ Cloud Architecture: MS Azure (ARM templates, AKS, Azure open AI models, Azure AD)\\nâ€¢ Frameworks/Others: Kubernetes, Kafka, Elasticsearch, Spark, NOSQL, RDBMS, Langchan, GIT\\n\\nWhat Youâ€™ll Do\\nâ€¢ Understands and analyze business requirements and assists in design for accuracy and completeness.\\nâ€¢ Develops and maintains relevant product.\\nâ€¢ Demonstrates good understanding of the product and owns one or more modules\\n\\nWhat We Are Looking For\\nâ€¢ BE/B. Tech or ME/M. Tech or MCA with 2.6 to 4.5 years of experience in Software Development of large and complex enterprise applications.\\nâ€¢ Experience in developing enterprise application using Python (Django, Flask, FastAPI preferred), GIT, Rest API.\\nâ€¢ Develops and maintains relevant product and domain knowledge\\nâ€¢ Develops and executes Unit Tests\\nâ€¢ Follows standard processes and procedures\\nâ€¢ Identifies reusable components\\nâ€¢ Ensures that the code is delivered for Integration Build and Test which includes the release content\\nâ€¢ Identifies and resolves software bugs\\nâ€¢ Tests and integrates with other development tasks\\nâ€¢ Adheres to the performance benchmark based on pre-defined requirements\\nâ€¢ Possesses knowledge of database architecture and data models used in the relevant product.\\nâ€¢ Plans and prioritizes work\\nâ€¢ Proactively reports all activities to the reporting managers\\nâ€¢ Proactively seeks assistance as required\\nâ€¢ Provide assistance or guidance to the new members of the team\\nâ€¢ Demonstrates problem solving and innovation ability.\\nâ€¢ Participates in company technical evaluations and coding challenges.\\n\\nOur Values\\n\\nIf you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success â€“ and the success of our customers. Does your heart beat like ours? Find out here: Core Values\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Software Engineer -(Jmeter,Sql, Java/ Python, Performance Engineer)\",\n",
      "      \"company_name\": \"Blue Yonder\",\n",
      "      \"application_link\": \"https://in.linkedin.com/jobs/view/software-engineer-jmeter-sql-java-python-performance-engineer-at-blue-yonder-4215109474?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\",\n",
      "      \"description\": \"Scope\\nâ€¢ As a Performance Test Engineer, you will be responsible for driving performance testing across web-based enterprise applications.\\nâ€¢ You will take complete ownership of the Performance Testing Lifecycle (PTLC)â€”including requirement gathering, scripting, test execution, analysis, and reporting. Youâ€™ll work under the guidance of a Performance Manager & Architect and collaborate closely with cross-functional teams to ensure the scalability, stability, and responsiveness of our applications.\\n\\nOur Current Technical Environment\\nâ€¢ Performance Testing Tools: Apache JMeter (Must Have),\\nâ€¢ Monitoring Tools: AppDynamics, Azure Monitor, Grafana, or similar\\nâ€¢ Languages & Frameworks: Java, REST APIs\\nâ€¢ Cloud Platforms: Azure (experience preferred)\\nâ€¢ Databases: SQL Server\\nâ€¢ Development Methodologies: Agile\\n\\nWhat Youâ€™ll Do\\nâ€¢ Conduct performance testing for enterprise web applications.\\nâ€¢ Take full ownership of PTLCâ€”from NFR gathering and scripting to execution and reporting.\\nâ€¢ Create, execute, and maintain performance test scripts using Apache JMeter.\\nâ€¢ Monitor key performance metrics during test runs and identify system bottlenecks.\\nâ€¢ Collaborate with developers, QA, DevOps, and architects to tune performance and optimize system behaviour.\\nâ€¢ Proactively update progress to reporting managers and escalate issues as needed.\\nâ€¢ Provide support and guidance to junior team members as required.\\n\\nWhat We Are Looking For\\nâ€¢ Strong foundation in performance testing concepts and best practices.\\nâ€¢ Hands-on experience with performance testing tools (Apache JMeter is mandatory).\\nâ€¢ Knowledge of performance monitoring and interpreting key metrics to assess system health.\\nâ€¢ Exposure to cloud-based environments (preferably Azure) is a plus.\\nâ€¢ Basic understanding of SQL and backend validation techniques.\\nâ€¢ Familiarity with scripting for automation is an added advantage.\\n\\nOur Values\\n\\nIf you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success â€“ and the success of our customers. Does your heart beat like ours? Find out here: Core Values\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "matched_jobs = match_jobs(resume_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb167d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_jobs = json.loads(matched_jobs)\n",
    "\n",
    "#Simulate user selecting a job\n",
    "selected_index = 0  \n",
    "selected_job = matched_jobs[\"matched_jobs\"][selected_index]\n",
    "\n",
    "selected_title = selected_job[\"title\"]\n",
    "selected_company = selected_job[\"company_name\"]\n",
    "selected_description = selected_job[\"description\"]\n",
    "\n",
    "# Generate the cover letter\n",
    "cover_letter = generate_cover_letter(\n",
    "    resume_json=resume_json,\n",
    "    selected_job_title=selected_title,\n",
    "    selected_job_description=selected_description,\n",
    "    company_name=selected_company\n",
    ")\n",
    "\n",
    "# 5. Save the cover letter to a file\n",
    "def save_cover_letter_to_txt(cover_letter, filename=\"cover_letter.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cover_letter)\n",
    "\n",
    "save_cover_letter_to_txt(cover_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1329bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
